{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExCaLBBR/ExCaLBBR_Projects/blob/main/RaciallyBiasedDecisions/RaciallyBiasedDecisions_APF/behavioral/code/RBD_IAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bfrwIu2GvzIP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "import pandas as pd #for dealing with csv import\n",
        "import os # for joining paths and filenames sensibly\n",
        "import numpy as np #for the population std\n",
        "import glob # for finding csv data files\n",
        "import platform # paths use different dividers on linux vs windows, so we need to test for this\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Utility functions\n",
        "#Compute adjusted mean\n",
        "def adjustedmean(RTs,corrs,penalty):\n",
        "    n=len(corrs) #trials\n",
        "    n_errors=int(n-sum(corrs)) #errors\n",
        "    # print(\"Number of correctness: \", int(sum(corrs)))\n",
        "    # print(\"Number of errors: \", n_errors)\n",
        "    cor_RTs=np.array(corrs)*RTs #sum of correct RTs\n",
        "    cor_mean=sum(cor_RTs)/sum(corrs)\n",
        "\n",
        "    #mean with errors replaced with penalty value\n",
        "    return cor_mean+(n_errors*penalty)/n\n",
        "\n",
        "\n",
        "#Remove timed out trials\n",
        "def exclude_slows(RTs,corrs,slowRT_limit):\n",
        "    new_rt=[] #holding variables\n",
        "    new_cr=[]\n",
        "    for i in range(len(RTs)): #iterate over every item\n",
        "        if RTs[i] < slowRT_limit: #if it isn't too fast, include RT and corr values\n",
        "            new_rt.append(RTs[i])\n",
        "            new_cr.append(corrs[i])\n",
        "\n",
        "    return (new_rt, new_cr)\n",
        "\n",
        "#Compute IAT bias rating\n",
        "def iat_analyze(congr_rts_raw, congr_corr_raw, incon_rts_raw, incon_corr_raw, df_name):\n",
        "    #1 discard subject if too many fast responses\n",
        "    if sum(np.array(congr_rts_raw + incon_rts_raw)<fastRT_limit)>len(congr_rts_raw + incon_rts_raw)*fast_prop_limit:\n",
        "        print (\"excluding subject for BM STR because too many fast responses\")\n",
        "    else:\n",
        "        #2 Eliminate scores over 10,000 ms\n",
        "\n",
        "        congr_rts,congr_corr=exclude_slows(congr_rts_raw,congr_corr_raw,slowRT_limit)\n",
        "        incon_rts,incon_corr=exclude_slows(incon_rts_raw,incon_corr_raw,slowRT_limit)\n",
        "\n",
        "        #3 Calculate pooled std\n",
        "        #pooled_std=pooled.std(0) #n-1 std sample std\n",
        "        #(Use N not N-1 because this is the whole sample).\n",
        "        #numpy.std is population std\n",
        "        pooled=congr_rts + incon_rts #all RTs from both blocks, correct and incorrect\n",
        "        pooled_std=np.std(pooled)\n",
        "\n",
        "        #4 Calculated adjusted means, including the penalty\n",
        "        congr_adjmean=adjustedmean(congr_rts,congr_corr,penalty)\n",
        "        incon_adjmean=adjustedmean(incon_rts,incon_corr,penalty)\n",
        "\n",
        "        #5 Calculate the IAT, so that pro-stereotype RTs are a -ve score\n",
        "        IAT=(congr_adjmean-incon_adjmean)/pooled_std\n",
        "\n",
        "        simpleIAT=sum(congr_rts)/len(congr_rts)-sum(incon_rts)/len(incon_rts)\n",
        "\n",
        "        return(iatBias)\n",
        "        print(\"IAT for \" + df_name + \" is : {:+.3f}\".format(IAT))\n",
        "        print(\"Mean difference (uncorrected) \" + df_name + \" is {:+.3f}\".format(simpleIAT)+\" seconds\")"
      ],
      "metadata": {
        "id": "E0gHEfHpv8s8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load data\n",
        "df_IAT_BM = pd.read_csv ('https://github.com/ExCaLBBR/ExCaLBBR_Projects/raw/main/RaciallyBiasedDecisions/RaciallyBiasedDecisions-Intersectionality_SURG/data/IAT_BM.csv', header=0)\n",
        "df_IAT_WM = pd.read_csv ('https://github.com/ExCaLBBR/ExCaLBBR_Projects/raw/main/RaciallyBiasedDecisions/RaciallyBiasedDecisions-Intersectionality_SURG/data/IAT_WM.csv', header=0)"
      ],
      "metadata": {
        "id": "uoFax7EbwSX0",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Specify thresholds\n",
        "penalty=0.600 #penalty - in seconds - for incorrect responses\n",
        "slowRT_limit=10000 #threshold at which slow RTs are discarded\n",
        "fastRT_limit=300 #threshold which defines responses which are \"too fast\"\n",
        "fast_prop_limit=0.1 # threshold proportion of \"too fast\" responses which defines exclusion of ppt\n"
      ],
      "metadata": {
        "id": "0IFRSKkDwaj7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Extraction\n",
        "df_IAT_BM.rename(columns={\"Spreadsheet: metadata\": \"Congruence\", \"allocator-k3xu\": \"Group Type\"}, inplace = True)\n",
        "df_IAT_BM_2 = df_IAT_BM.drop([\"Spreadsheet: ImageLeft\", \"Spreadsheet: ImageRight\"], axis = 1)\n",
        "df_IAT_WM.rename(columns={\"Spreadsheet: metadata\": \"Congruence\", \"allocator-k3xu\": \"Group Type\"}, inplace = True)\n",
        "df_IAT_WM_2 = df_IAT_WM.drop([\"Spreadsheet: ImageLeft\", \"Spreadsheet: ImageRight\"], axis = 1)\n",
        "\n",
        "#Isolate columns based on stereotype category which are not part of the practice blocks\n",
        "df_IAT_BM_STR = df_IAT_BM_2[((df_IAT_BM_2[\"Spreadsheet: TextLeft\"] == \"Strong\") | (df_IAT_BM_2[\"Spreadsheet: TextRight\"] == \"Strong\")) & (~df_IAT_BM_2[\"Congruence\"].str.startswith(\"practice\"))]\n",
        "df_IAT_BM_INT = df_IAT_BM_2[((df_IAT_BM_2[\"Spreadsheet: TextLeft\"] == \"Intelligence\") | (df_IAT_BM_2[\"Spreadsheet: TextRight\"] == \"Intelligence\")) & (~df_IAT_BM_2[\"Congruence\"].str.startswith(\"practice\"))]\n",
        "df_IAT_WM_STR = df_IAT_WM_2[((df_IAT_WM_2[\"Spreadsheet: TextLeft\"] == \"Strong\") | (df_IAT_WM_2[\"Spreadsheet: TextRight\"] == \"Strong\")) & (~df_IAT_WM_2[\"Congruence\"].str.startswith(\"practice\"))]\n",
        "df_IAT_WM_INT = df_IAT_WM_2[((df_IAT_WM_2[\"Spreadsheet: TextLeft\"] == \"Intelligence\") | (df_IAT_WM_2[\"Spreadsheet: TextRight\"] == \"Intelligence\")) & (~df_IAT_WM_2[\"Congruence\"].str.startswith(\"practice\"))]\n",
        "\n",
        "# BM STR lists RV: polarity of the condition was mislabed in the original data and is corrected here\n",
        "congr_BM_STR_ID = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"incongruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "congr_corr_BM_STR = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"incongruent\"][\"Correct\"].dropna().tolist()\n",
        "congr_rts_BM_STR = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"incongruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "incon_BM_STR_ID = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"congruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "incon_corr_BM_STR = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"congruent\"][\"Correct\"].dropna().tolist()\n",
        "incon_rts_BM_STR = df_IAT_BM_STR[df_IAT_BM_STR[\"Congruence\"] == \"congruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "# BM INT lists\n",
        "congr_BM_INT_ID = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"congruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "congr_corr_BM_INT = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"congruent\"][\"Correct\"].dropna().tolist()\n",
        "congr_rts_BM_INT = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"congruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "incon_BM_INT_ID = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"incongruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "incon_corr_BM_INT = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"incongruent\"][\"Correct\"].dropna().tolist()\n",
        "incon_rts_BM_INT = df_IAT_BM_INT[df_IAT_BM_INT[\"Congruence\"] == \"incongruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "# WM STR lists RV: polarity of the condition was mislabed in the original data and is corrected here\n",
        "congr_WM_STR_ID = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"incongruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "congr_corr_WM_STR = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"incongruent\"][\"Correct\"].dropna().tolist()\n",
        "congr_rts_WM_STR = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"incongruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "incon_WM_STR_ID = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"congruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "incon_corr_WM_STR = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"congruent\"][\"Correct\"].dropna().tolist()\n",
        "incon_rts_WM_STR = df_IAT_WM_STR[df_IAT_WM_STR[\"Congruence\"] == \"congruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "# WM INT lists\n",
        "congr_WM_INT_ID = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"congruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "congr_corr_WM_INT = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"congruent\"][\"Correct\"].dropna().tolist()\n",
        "congr_rts_WM_INT = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"congruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "incon_WM_INT_ID = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"incongruent\"][\"Participant Private ID\"].dropna().tolist()\n",
        "incon_corr_WM_INT = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"incongruent\"][\"Correct\"].dropna().tolist()\n",
        "incon_rts_WM_INT = df_IAT_WM_INT[df_IAT_WM_INT[\"Congruence\"] == \"incongruent\"][\"Absolute Reaction Time\"].dropna().tolist()\n",
        "# check correctness list has the same length as the rt list\n",
        "# print(len(congr_corr_BM_STR))\n",
        "# print(len(congr_rts_BM_STR))\n"
      ],
      "metadata": {
        "id": "HLJdf6IoSQcT",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BM_ID = np.unique(congr_BM_STR_ID)"
      ],
      "metadata": {
        "id": "-zWzrYmiza7K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0\n",
        "BM_ID[p]\n",
        "print (\"excluding subject\", BM_ID[p], \"for BM STR because too many fast responses\")"
      ],
      "metadata": {
        "id": "Dw9KyBL5zcbq",
        "outputId": "dad8212a-b22c-4bb3-e049-180770b1ccc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excluding subject 8657248.0 for BM STR because too many fast responses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Filter participants who are too fast\n",
        "#Find and remove participants who are too fast\n",
        "BM_ID = np.unique(congr_BM_STR_ID)\n",
        "remIndx = []\n",
        "for p in range(len(BM_ID)):\n",
        "    indx_cong = np.where(np.array(congr_BM_STR_ID) == BM_ID[p])\n",
        "    indx_incon = np.where(np.array(incon_BM_STR_ID) == BM_ID[p])\n",
        "    if sum(np.array(np.concatenate((np.array(congr_rts_BM_STR)[indx_cong], np.array(incon_rts_BM_STR)[indx_incon])))<fastRT_limit)>len(np.concatenate((np.array(congr_rts_BM_STR)[indx_cong], np.array(incon_rts_BM_STR)[indx_incon])))*fast_prop_limit:\n",
        "      print (\"Excluding subject\", BM_ID[p], \"for BM STR because too many fast responses\")\n",
        "      remIndx.append(p)\n",
        "BM_ID_filt = np.delete(BM_ID, remIndx)\n",
        "\n",
        "remIndx = []\n",
        "for p in range(len(BM_ID_filt)):\n",
        "    indx_cong = np.where(np.array(congr_BM_INT_ID) == BM_ID_filt[p])\n",
        "    indx_incon = np.where(np.array(incon_BM_INT_ID) == BM_ID_filt[p])\n",
        "    if sum(np.array(np.concatenate((np.array(congr_rts_BM_INT)[indx_cong], np.array(incon_rts_BM_INT)[indx_incon])))<fastRT_limit)>len(np.concatenate((np.array(congr_rts_BM_INT)[indx_cong], np.array(incon_rts_BM_INT)[indx_incon])))*fast_prop_limit:\n",
        "      print (\"Excluding subject\", BM_ID_filt[p], \"for BM INT because too many fast responses\")\n",
        "      remIndx.append(p)\n",
        "BM_ID_filt = np.delete(BM_ID_filt, remIndx)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E1c0ZiTO0joj",
        "outputId": "9a43f127-b518-4729-c6f2-3c8b9de1ca53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excluding subject 8657542.0 for BM STR because too many fast responses\n",
            "Excluding subject 8657619.0 for BM STR because too many fast responses\n",
            "Excluding subject 8657695.0 for BM STR because too many fast responses\n",
            "Excluding subject 8657698.0 for BM STR because too many fast responses\n",
            "Excluding subject 8660226.0 for BM STR because too many fast responses\n",
            "Excluding subject 8663169.0 for BM STR because too many fast responses\n",
            "Excluding subject 8657248.0 for BM INT because too many fast responses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute IAT bias\n",
        "#\n",
        "BM_IAT_STR = []\n",
        "for p in range(len(BM_ID_filt)):\n",
        "  indx_cong = np.where(np.array(congr_BM_STR_ID) == BM_ID_filt[p])[0]\n",
        "  cong_corr_BM_STR_pi = np.array(congr_corr_BM_STR)[indx_cong]\n",
        "  cong_rts_BM_STR_pi = np.array(congr_rts_BM_STR)[indx_cong]\n",
        "  indx_incon = np.where(np.array(incon_BM_STR_ID) == BM_ID_filt[p])[0]\n",
        "  incon_corr_BM_STR_pi = np.array(incon_corr_BM_STR)[indx_incon]\n",
        "  incon_rts_BM_STR_pi = np.array(incon_rts_BM_STR)[indx_incon]\n",
        "  print(BM_ID_filt[p])\n",
        "  iat_analyze(cong_rts_BM_STR_pi, cong_corr_BM_STR_pi, incon_rts_BM_STR_pi, incon_corr_BM_STR_pi, \"BM STR\")\n",
        "  BM_IAT_STR.append(iatBias)"
      ],
      "metadata": {
        "id": "cf_OQd7CUtm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(BM_ID[50])"
      ],
      "metadata": {
        "id": "W6A0bAwKehfR",
        "outputId": "4b697cc2-5799-4e66-c03f-c93a49009737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8657580.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Groupwise Analysis\n",
        "iat_analyze(congr_rts_BM_STR, congr_corr_BM_STR, incon_rts_BM_STR, incon_corr_BM_STR, \"BM STR\")\n",
        "iat_analyze(congr_rts_BM_INT, congr_corr_BM_INT, incon_rts_BM_INT, incon_corr_BM_INT, \"BM INT\")\n",
        "iat_analyze(congr_rts_WM_STR, congr_corr_WM_STR, incon_rts_WM_STR, incon_corr_WM_STR, \"WM STR\")\n",
        "iat_analyze(congr_rts_WM_INT, congr_corr_WM_INT, incon_rts_WM_INT, incon_corr_WM_INT, \"WM INT\")"
      ],
      "metadata": {
        "id": "iAxbLnaciRlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb195da-540e-4238-e22a-157b824d6e16"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IAT for BM STR is : -0.039\n",
            "Mean difference (uncorrected) BM STR is -25.912 seconds\n",
            "IAT for BM INT is : -0.004\n",
            "Mean difference (uncorrected) BM INT is -3.615 seconds\n",
            "IAT for WM STR is : -0.029\n",
            "Mean difference (uncorrected) WM STR is -9.578 seconds\n",
            "IAT for WM INT is : -0.175\n",
            "Mean difference (uncorrected) WM INT is -88.064 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deprecated functions and declarations"
      ],
      "metadata": {
        "id": "iHtFpagJCfjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #extract the stuff we're interested in (n.b i am indexing using the column names defined in the csv)\n",
        "#     #dropna() drops nans\n",
        "#     #tolist() converts from series to list\n",
        "#     corrs=df['key_resp_9.corr'].dropna().tolist()\n",
        "#     rts=df['key_resp_9.rt'].dropna().tolist()\n",
        "#     block_length=int(len(corrs)/2)\n",
        "#     #find order\n",
        "#     order=df['order'].tolist()[0]\n",
        "#     #1 congr then incong\n",
        "#     #2 incongr then congr\n",
        "#     if order==1:\n",
        "#         congr_corr=corrs[0:block_length]\n",
        "#         congr_rts=rts[0:block_length]\n",
        "#         incon_corr=corrs[block_length:]\n",
        "#         incon_rts=rts[block_length:]\n",
        "#     else:\n",
        "#         congr_corr=corrs[block_length:]\n",
        "#         congr_rts=rts[block_length:]\n",
        "#         incon_corr=corrs[0:block_length]\n",
        "#         incon_rts=rts[0:block_length]\n",
        "#     #1 discard subject if too many fast responses\n",
        "#     if sum(np.array(congr_rts + incon_rts)<fastRT_limit)>len(congr_rts + incon_rts)*fast_prop_limit:\n",
        "#         print \"excluding subject for \" + os.path.basename(filename) + \" because too many fast responses\"\n",
        "#     else:\n",
        "#         #2 Eliminate scores over 10,000 ms\n",
        "\n",
        "#         congr_rts,congr_corr=exclude_slows(congr_rts,congr_corr,slowRT_limit)\n",
        "#         incon_rts,incon_corr=exclude_slows(incon_rts,incon_corr,slowRT_limit)\n",
        "\n",
        "#         #3 Calculate pooled std\n",
        "#         #pooled_std=pooled.std(0) #n-1 std sample std\n",
        "#         #(Use N not N-1 because this is the whole sample).\n",
        "#         #numpy.std is population std\n",
        "#         pooled=congr_rts + incon_rts #all RTs from both blocks, correct and incorrect\n",
        "#         pooled_std=np.std(pooled)\n",
        "\n",
        "#         #4 Calculated adjusted means, including the penalty\n",
        "#         congr_adjmean=adjustedmean(congr_rts,congr_corr,penalty)\n",
        "#         incon_adjmean=adjustedmean(incon_rts,incon_corr,penalty)\n",
        "\n",
        "#         #5 Calculate the IAT, so that pro-stereotype RTs are a -ve score\n",
        "#         IAT=(congr_adjmean-incon_adjmean)/pooled_std\n",
        "\n",
        "#         simpleIAT=mean(congr_rts)-mean(incon_rts)\n",
        "\n",
        "#         print \"IAT for \" + os.path.basename(filename) + \" is : {:+.3f}\".format(IAT)\n",
        "#         print \"Mean difference (uncorrected) is {:+.3f}\".format(simpleIAT)+\" seconds\"\n",
        "# df_IAT_BM_INT_inin = df_IAT_BM_INT[df_IAT_BM_INT[\"Group Type\"] == \"Condition_InIn\"]\n",
        "# df_IAT_BM_INT_inoutGender = df_IAT_BM_INT[df_IAT_BM_INT[\"Group Type\"] == \"Condition_InOut-gender\"]\n",
        "# df_IAT_BM_INT_inoutRace = df_IAT_BM_INT[df_IAT_BM_INT[\"Group Type\"] == \"Condition_InOut-race\"]\n",
        "# df_IAT_BM_INT_inoutBoth = df_IAT_BM_INT[df_IAT_BM_INT[\"Group Type\"] == \"Condition_InOut-both\"]\n",
        "# df_IAT_WM_INT_inin = df_IAT_WM_INT[df_IAT_WM_INT[\"Group Type\"] == \"Condition_InIn\"]\n",
        "# df_IAT_WM_INT_inoutGender = df_IAT_WM_INT[df_IAT_WM_INT[\"Group Type\"] == \"Condition_InOut-gender\"]\n",
        "# df_IAT_WM_INT_inoutRace = df_IAT_WM_INT[df_IAT_WM_INT[\"Group Type\"] == \"Condition_InOut-race\"]\n",
        "# df_IAT_WM_INT_inoutBoth = df_IAT_WM_INT[df_IAT_WM_INT[\"Group Type\"] == \"Condition_InOut-both\"]"
      ],
      "metadata": {
        "id": "BInUNoXhCjbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference:\n",
        "IAT data analysis script adapted from https://github.com/tomstafford/IAT\n",
        "\n",
        "Calculate IAT score from data generated by Robin's PsychoPy script [TQS Feb 2014]\n",
        "\n",
        "*Greenwald, A. G., Nosek, B. A., & Banaji, M. R. (2003). Understanding and using the implicit association test: I. An improved scoring algorithm. Journal of personality and social psychology, 85(2), 1972-216.*"
      ],
      "metadata": {
        "id": "pE-DC6j9wKGk"
      }
    }
  ]
}