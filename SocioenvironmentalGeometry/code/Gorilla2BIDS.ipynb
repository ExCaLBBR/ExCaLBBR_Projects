{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExCaLBBR/ExCaLBBR_Projects/blob/main/SocioenvironmentalGeometry/code/Gorilla2BIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gorilla Info: <br>\n",
        "Project: SocioenvironmentalConceptGeometry <br>\n",
        "Version: 9 <br>\n",
        "Account: Roberto Vargas (robertov@andrew.cmu.edu) "
      ],
      "metadata": {
        "id": "C9mud3ByqVgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load relevant libraries and install dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "08gBma2_ivoE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert values in the pivot values from list to float for PRaM and SPaM\n",
        "\n",
        "def convert_to_float(x):\n",
        "    if isinstance(x, list):\n",
        "        return float(x[0]) # assuming there is only one value in the list\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "3dArzVdYA-mz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Data:\n",
        "\n",
        "#QUESTIONAIRRES:\n",
        "#Demographics\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_demographic.csv'\n",
        "df_demographic = pd.read_csv(url)\n",
        "\n",
        "#Ethnic Identity\n",
        "url ='https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_EthnicIdentity.csv'\n",
        "df_EthId = pd.read_csv(url)\n",
        "\n",
        "#Multidimensional Inventory of Black Identity\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_MIBI.csv'\n",
        "df_MIBI = pd.read_csv(url)\n",
        "\n",
        "#News Consumption\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_NewsConsumption.csv'\n",
        "df_News = pd.read_csv(url)\n",
        "\n",
        "#Gender/Racial Discrimination\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_GR-Discrim.csv'\n",
        "df_GRDiscrim = pd.read_csv(url)\n",
        "\n",
        "#Concept Exposure\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptExposure.csv'\n",
        "df_ConExposure = pd.read_csv(url)\n",
        "\n",
        "#Concept Feeling\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptFeeling.csv'\n",
        "df_ConFeeling = pd.read_csv(url)\n",
        "\n",
        "#Concept Interaction\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptInteraction.csv'\n",
        "df_ConInteraction = pd.read_csv(url)\n",
        "\n",
        "#Social Dominance Orientation\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_SDO.csv'\n",
        "df_SDO = pd.read_csv(url)\n",
        "\n",
        "\n",
        "#TASKS:\n",
        "#PRaM\n",
        "url = 'https://github.com/ExCaLBBR/ExCaLBBR_Projects/raw/main/SocioenvironmentalGeometry/data/raw/raw_task_PRaM.csv.gz'\n",
        "df_taskPRaM = pd.read_csv(url, compression='gzip')\n",
        "\n",
        "#SpAM\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_task_SpAM.csv'\n",
        "df_taskSpAM = pd.read_csv(url)\n",
        "\n",
        "#Default values \n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/defaultCoordinates.csv'\n",
        "df_default_values = pd.read_csv(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA7mXjvZZldd",
        "outputId": "a1f29cfe-d4b4-413c-94d4-081d67be92d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-a337d915c2c7>:44: DtypeWarning: Columns (0,35,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_taskPRaM = pd.read_csv(url, compression='gzip')\n",
            "<ipython-input-14-a337d915c2c7>:48: DtypeWarning: Columns (0,15,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_taskSpAM = pd.read_csv(url)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Isolate relevant columns: Demographics\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_demographic = df_demographic[~df_demographic['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_demographic.drop(columns=df_demographic.columns.difference(include), inplace=True)\n",
        "mask = df_demographic['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_demographic['Question Key'].str.contains('END QUESTIONNAIRE', na=True) | df_demographic['Question Key'].str.contains('quantised', na=True) | df_demographic['Question Key'].str.contains('response-2', na=True)\n",
        "df_demographic = df_demographic[~mask]\n",
        "df_demographic = df_demographic.dropna()\n",
        "#display(df_demographic)\n",
        "\n",
        "#Isolate relevant columns: Ethnic Identity\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_EthId = df_EthId[~df_EthId['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_EthId.drop(columns=df_EthId.columns.difference(include), inplace=True)\n",
        "mask = df_EthId['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_EthId['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_EthId = df_EthId[~mask]\n",
        "df_EthId = df_EthId.dropna()\n",
        "#display(df_EthId)\n",
        "\n",
        "#Isolate relevant columns: Multidimensional Inventory of Black Identity\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_MIBI = df_MIBI[~df_MIBI['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_MIBI.drop(columns=df_MIBI.columns.difference(include), inplace=True)\n",
        "mask = df_MIBI['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_MIBI['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_MIBI = df_MIBI[~mask]\n",
        "df_MIBI = df_MIBI.dropna()\n",
        "#display(df_MIBI)\n",
        "\n",
        "#Isolate relevant columns: News Consumption\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_News = df_News[~df_News['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_News.drop(columns=df_News.columns.difference(include), inplace=True)\n",
        "mask = df_News['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_News['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_News = df_News[~mask]\n",
        "df_News = df_News.dropna()\n",
        "#display(df_News)\n",
        "\n",
        "#Isolate relevant columns: Gender/Racial Discrimination\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_GRDiscrim = df_GRDiscrim[~df_GRDiscrim['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_GRDiscrim.drop(columns=df_GRDiscrim.columns.difference(include), inplace=True)\n",
        "mask = df_GRDiscrim['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_GRDiscrim['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_GRDiscrim = df_GRDiscrim[~mask]\n",
        "df_GRDiscrim = df_GRDiscrim.dropna()\n",
        "#display(df_GRDiscrim)\n",
        "\n",
        "#Isolate relevant columns: Concept Exposure\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_ConExposure = df_ConExposure[~df_ConExposure['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConExposure.drop(columns=df_ConExposure.columns.difference(include), inplace=True)\n",
        "mask = df_ConExposure['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConExposure['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConExposure = df_ConExposure[~mask]\n",
        "df_ConExposure = df_ConExposure.dropna()\n",
        "#display(df_ConExposure)\n",
        "\n",
        "#Isolate relevant columns: Concept Feeling\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_ConFeeling = df_ConFeeling[~df_ConFeeling['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConFeeling.drop(columns=df_ConFeeling.columns.difference(include), inplace=True)\n",
        "mask = df_ConFeeling['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConFeeling['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConFeeling = df_ConFeeling[~mask]\n",
        "df_ConFeeling = df_ConFeeling.dropna()\n",
        "#display(df_ConFeeling)\n",
        "\n",
        "#Isolate relevant columns: Concept Interaction\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_ConInteraction = df_ConInteraction[~df_ConInteraction['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConInteraction.drop(columns=df_ConInteraction.columns.difference(include), inplace=True)\n",
        "mask = df_ConInteraction['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConInteraction['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConInteraction = df_ConInteraction[~mask]\n",
        "df_ConInteraction = df_ConInteraction.dropna()\n",
        "#display(df_ConInteraction)\n",
        "\n",
        "#Isolate relevant columns: Social Dominance Orientation\n",
        "include = ['Participant Private ID', 'Question Key', 'Response']\n",
        "#df_SDO = df_SDO[~df_SDO['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_SDO.drop(columns=df_SDO.columns.difference(include), inplace=True)\n",
        "mask = df_SDO['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_SDO['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_SDO = df_SDO[~mask]\n",
        "df_SDO = df_SDO.dropna()\n",
        "#display(df_SDO)\n",
        "\n",
        "#Isolate relevant columns: PRaM\n",
        "include = ['Participant Private ID', 'Zone Name', 'conceptA', 'conceptB', 'Response']\n",
        "df_taskPRaM.drop(columns=df_taskPRaM.columns.difference(include), inplace=True)\n",
        "mask = df_taskPRaM['Zone Name'].str.contains('Likert', na=True)\n",
        "df_taskPRaM = df_taskPRaM[mask]\n",
        "df_taskPRaM = df_taskPRaM.dropna()\n",
        "df_taskPRaM.drop(columns=['Zone Name'], inplace=True)\n",
        "df_taskPRaM['Pair'] = df_taskPRaM['conceptA'] + '-' + df_taskPRaM['conceptB']\n",
        "df_taskPRaM.drop(columns=['conceptA', 'conceptB'], inplace=True)\n",
        "# display(df_taskPRaM)\n",
        "\n",
        "# #Isolate relevant columns: SpAM\n",
        "#Isolate relevant columns: SpAM\n",
        "include = ['Participant Private ID', 'Zone Name', 'Zone Type', 'Response']\n",
        "df_taskSpAM = df_taskSpAM[:-1]\n",
        "mask = df_taskSpAM['Trial Number'].str.contains('BEGIN TASK', na=True) | df_taskSpAM['Trial Number'].str.contains('END TASK', na=True)\n",
        "df_taskSpAM = df_taskSpAM[~mask]\n",
        "df_taskSpAM.drop(columns=df_taskSpAM.columns.difference(include), inplace=True)\n",
        "mask = df_taskSpAM['Zone Type'].str.contains('drag_and_drop_main', na=True) | df_taskSpAM['Zone Name'].str.contains('Zone10', na=True) \n",
        "df_taskSpAM = df_taskSpAM[mask]\n",
        "df_taskSpAM.drop(columns=['Zone Type'], inplace=True)\n",
        "df_taskSpAM['Zone Name'] = df_taskSpAM['Zone Name'].replace(['conceptA', 'conceptB', 'conceptC', 'conceptD', 'conceptE', 'conceptF', 'conceptG'], ['Police', 'Firefighter', 'Neighbors', 'Conservatives', 'Liberals', 'Healthcare', 'Voting'])\n",
        "df_taskSpAM = df_taskSpAM.dropna()\n",
        "#display(df_taskSpAM)\n",
        "\n",
        "#Isolate relevant columns: Default values\n",
        "include = ['Zone Name', 'Zone Type', 'Response']\n",
        "df_default_values = df_default_values[:-1]\n",
        "df_default_values.drop(columns=df_default_values.columns.difference(include), inplace=True)\n",
        "mask = df_default_values['Zone Type'].str.contains('drag_and_drop_main', na=True) | df_default_values['Zone Name'].str.contains('Zone10', na=True) \n",
        "df_default_values = df_default_values[mask]\n",
        "df_default_values.drop(columns=['Zone Type'], inplace=True)\n",
        "df_default_values['Zone Name'] = df_default_values['Zone Name'].replace(['conceptA', 'conceptB', 'conceptC', 'conceptD', 'conceptE', 'conceptF', 'conceptG'], ['Police', 'Firefighter', 'Neighbors', 'Conservatives', 'Liberals', 'Healthcare', 'Voting'])\n",
        "df_default_values = df_default_values.dropna()\n",
        "\n",
        "# List to separate the zone name and coordinates\n",
        "zone_name = df_default_values['Zone Name'].to_list()\n",
        "coordinates = df_default_values['Response'].to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LwvqmKec1MJ",
        "outputId": "4dabb173-b04e-4901-f4be-7399c8883699"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-9257851e71c5>:110: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_default_values.drop(columns=df_default_values.columns.difference(include), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Isolate Pivot dataframes\n",
        "df_demographic = df_demographic.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Demographics\n",
        "#display(df_demographic)\n",
        "\n",
        "df_EthId = df_EthId.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Ethnic Identity\n",
        "#display(df_EthId)\n",
        "\n",
        "df_MIBI = df_MIBI.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Multidimensional Inventory of Black Identity\n",
        "#display(df_MIBI)\n",
        "\n",
        "df_News = df_News.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #News Consumption\n",
        "#display(df_News)\n",
        "\n",
        "df_GRDiscrim = df_GRDiscrim.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Gender/Racial Discrimination\n",
        "#display(df_GRDiscrim)\n",
        "\n",
        "df_ConExposure = df_ConExposure.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Concept Exposure\n",
        "#display(df_ConExposure)\n",
        "\n",
        "df_ConFeeling = df_ConFeeling.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Concept Feeling\n",
        "#display(df_ConFeeling)\n",
        "\n",
        "df_ConInteraction = df_ConInteraction.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Concept Interaction\n",
        "#display(df_ConInteraction)\n",
        "\n",
        "df_SDO = df_SDO.pivot(index = 'Participant Private ID', columns = ['Question Key'], values = ['Response']) #Social Dominance Orientation\n",
        "#display(df_SDO)\n",
        "\n",
        "#TASKS:\n",
        "#TODO: Take last mask out last instance of each concepts. If no isntance is present then use default coordinate. Flag participants that did not move at least half of the concepts (i.e., there are no entries)\n",
        "df_taskSpAM = df_taskSpAM.groupby(['Participant Private ID', 'Zone Name'])['Response'].agg(' '.join).reset_index()\n",
        "df_taskSpAM = df_taskSpAM.pivot(index='Participant Private ID', columns=['Zone Name'], values='Response')\n",
        "\n",
        "for i in range(df_taskSpAM.shape[0]):\n",
        "  for j in range(df_taskSpAM.shape[1]):\n",
        "    if pd.isna(df_taskSpAM.iloc[i,j]):\n",
        "      index = zone_name.index(df_taskSpAM.columns[j])\n",
        "      df_taskSpAM.iloc[i,j] = coordinates[index]\n",
        "\n",
        "# Select the last coordinate input\n",
        "df_taskSpAM = df_taskSpAM.apply(lambda x: x.str.split(' ').str[-4:])\n",
        "df_taskSpAM = df_taskSpAM.applymap(lambda x: [x[0], x[2]] if isinstance(x, list) else x)\n",
        "df_taskSpAM = df_taskSpAM.applymap(lambda x: [int(''.join(filter(str.isdigit, i))) for i in x])\n",
        "#display(df_taskSpAM)\n",
        "\n",
        "#Solution\n",
        "# group values by index column and aggregating the Response values as list. \n",
        "df_taskPRaM = df_taskPRaM.groupby(['Participant Private ID', 'Pair'])['Response'].agg(list).reset_index()\n",
        "df_taskPRaM = df_taskPRaM.pivot(index='Participant Private ID', columns='Pair', values='Response')\n",
        "\n",
        "# Run the following function to convert Response values from list to float.\n",
        "df_taskPRaM = df_taskPRaM.applymap(convert_to_float)\n",
        "#display(df_taskPRaM)"
      ],
      "metadata": {
        "id": "8dzVwNOoDY5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "8b9340b8-e47e-4c3b-9644-5d2fab437897"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Participant Private ID'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-58211d49f014>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#display(df_MIBI)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_News\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_News\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Participant Private ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Question Key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#News Consumption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#display(df_News)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   8565\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8567\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8569\u001b[0m     _shared_docs[\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Participant Private ID'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Push to Lab GitHub !!!\n",
        "#NOTE: These credentials should be configured to user's lab GitHub\n",
        "#If user is part of ExCaLBBR Lab then ask Roberto for access\n",
        "!git config --global user.name \"\" #\"YOUR CREDIENTIALS HERE\" \n",
        "!git config --global user.email \"\" #\"YOUR CREDIENTIALS HERE\"\n",
        "!git config --global user.password \"\" #\"YOUR CREDIENTIALS HERE\"\n",
        "\n",
        "token = ''\n",
        "username_organization = ''\n",
        "repo = ''\n",
        "outputDir = ''"
      ],
      "metadata": {
        "id": "P1hSBfkRJkYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone repository and move created files into output directory\n",
        "!git clone https://{token}@github.com/{username_organization}/{repo}"
      ],
      "metadata": {
        "id": "RToVhxKCJntE",
        "outputId": "bc28fd19-bc68-4924-b409-f0acab8aaebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ExCaLBBR_Projects'...\n",
            "remote: Enumerating objects: 543, done.\u001b[K\n",
            "remote: Counting objects: 100% (324/324), done.\u001b[K\n",
            "remote: Compressing objects: 100% (241/241), done.\u001b[K\n",
            "remote: Total 543 (delta 115), reused 217 (delta 78), pack-reused 219\u001b[K\n",
            "Receiving objects: 100% (543/543), 13.25 MiB | 25.51 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert all files to csv\n",
        "df_demographic.to_csv('demographic.csv')\n",
        "df_EthId.to_csv('df_EthId.csv')\n",
        "df_MIBI.to_csv('df_MIBI.csv')\n",
        "df_News.to_csv('df_News.csv')\n",
        "df_GRDiscrim.to_csv('df_GRDiscrim.csv')\n",
        "df_ConExposure.to_csv('df_ConExposure.csv')\n",
        "df_ConFeeling.to_csv('df_ConFeeling.csv')\n",
        "df_ConInteraction.to_csv('df_ConInteraction.csv')\n",
        "df_SDO.to_csv('df_SDO.csv')\n",
        "df_taskSpAM.to_csv('df_taskSpAM.csv')\n",
        "df_taskPRaM.to_csv('df_taskPRaM.csv')"
      ],
      "metadata": {
        "id": "GHGoq3mGSf5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move files to Clone repository\n",
        "!mv demographic.csv {repo}/{outputDir}\n",
        "!mv df_EthId.csv {repo}/{outputDir}\n",
        "!mv df_MIBI.csv {repo}/{outputDir}\n",
        "!mv df_News.csv {repo}/{outputDir}\n",
        "!mv df_GRDiscrim.csv {repo}/{outputDir}\n",
        "!mv df_ConExposure.csv {repo}/{outputDir}\n",
        "!mv df_ConFeeling.csv {repo}/{outputDir}\n",
        "!mv df_ConInteraction.csv {repo}/{outputDir}\n",
        "!mv df_SDO.csv {repo}/{outputDir}\n",
        "!mv df_taskSpAM.csv {repo}/{outputDir}\n",
        "!mv df_taskPRaM.csv {repo}/{outputDir}"
      ],
      "metadata": {
        "id": "8QzFtkfER0-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move to principle dir, commit, and push changes\n",
        "%cd {repo}\n",
        "!git add --all\n",
        "!git commit -a -m \"Fixed issues with Isolate relevant columns: PRaM and SPaM\"\n",
        "!git push origin"
      ],
      "metadata": {
        "id": "GhSx52_aMfPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056e4d2e-ab1d-4932-f422-289648c169c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ExCaLBBR_Projects\n",
            "[main 0c81957] Fixed issues with Isolate relevant columns: PRaM and SPaM\n",
            " 11 files changed, 5598 insertions(+)\n",
            " create mode 100644 SocioenvironmentalGeometry/data/demographic.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_ConExposure.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_ConFeeling.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_ConInteraction.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_EthId.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_GRDiscrim.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_MIBI.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_News.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_SDO.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_taskPRaM.csv\n",
            " create mode 100644 SocioenvironmentalGeometry/data/df_taskSpAM.csv\n",
            "Enumerating objects: 18, done.\n",
            "Counting objects: 100% (18/18), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (15/15), done.\n",
            "Writing objects: 100% (15/15), 137.84 KiB | 3.06 MiB/s, done.\n",
            "Total 15 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/ExCaLBBR/ExCaLBBR_Projects\n",
            "   3bd9be8..0c81957  main -> main\n"
          ]
        }
      ]
    }
  ]
}