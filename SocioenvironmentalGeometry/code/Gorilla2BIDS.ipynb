{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExCaLBBR/ExCaLBBR_Projects/blob/main/SocioenvironmentalGeometry/code/Gorilla2BIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gorilla Info: <br>\n",
        "Project: SocioenvironmentalConceptGeometry <br>\n",
        "Version: 9 <br>\n",
        "Account: Roberto Vargas (robertov@andrew.cmu.edu) "
      ],
      "metadata": {
        "id": "C9mud3ByqVgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load relevant libraries and install dependencies\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "08gBma2_ivoE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert values in the pivot values from list to float for PRaM and SPaM\n",
        "\n",
        "def convert_to_float(x):\n",
        "    if isinstance(x, list):\n",
        "        return float(x[0]) # assuming there is only one value in the list\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "3dArzVdYA-mz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Data:\n",
        "\n",
        "#QUESTIONAIRRES:\n",
        "#Demographics\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_demographic.csv'\n",
        "df_demographic = pd.read_csv(url)\n",
        "\n",
        "#Ethnic Identity\n",
        "url ='https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_EthnicIdentity.csv'\n",
        "df_EthId = pd.read_csv(url)\n",
        "\n",
        "#Multidimensional Inventory of Black Identity\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_MIBI.csv'\n",
        "df_MIBI = pd.read_csv(url)\n",
        "\n",
        "#News Consumption\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_NewsConsumption.csv'\n",
        "df_News = pd.read_csv(url)\n",
        "\n",
        "#Gender/Racial Discrimination\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_GR-Discrim.csv'\n",
        "df_GRDiscrim = pd.read_csv(url)\n",
        "\n",
        "#Concept Exposure\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptExposure.csv'\n",
        "df_ConExposure = pd.read_csv(url)\n",
        "\n",
        "#Concept Feeling\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptFeeling.csv'\n",
        "df_ConFeeling = pd.read_csv(url)\n",
        "\n",
        "#Concept Interaction\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_ConceptInteraction.csv'\n",
        "df_ConInteraction = pd.read_csv(url)\n",
        "\n",
        "#Social Dominance Orientation\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_questionnaire_SDO.csv'\n",
        "df_SDO = pd.read_csv(url)\n",
        "\n",
        "\n",
        "#TASKS:\n",
        "#PRaM\n",
        "url = 'https://github.com/ExCaLBBR/ExCaLBBR_Projects/raw/main/SocioenvironmentalGeometry/data/raw/raw_task_PRaM.csv.gz'\n",
        "df_taskPRaM = pd.read_csv(url, compression='gzip')\n",
        "\n",
        "#SpAM\n",
        "url = 'https://raw.githubusercontent.com/ExCaLBBR/ExCaLBBR_Projects/main/SocioenvironmentalGeometry/data/raw/raw_task_SpAM.csv'\n",
        "df_taskSpAM = pd.read_csv(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA7mXjvZZldd",
        "outputId": "eadce35c-c736-4c10-f021-e406af0d20c8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0,35,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Isolate relevant columns: Demographics\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_demographic = df_demographic[~df_demographic['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_demographic.drop(columns=df_demographic.columns.difference(include), inplace=True)\n",
        "mask = df_demographic['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_demographic['Question Key'].str.contains('END QUESTIONNAIRE', na=True) | df_demographic['Question Key'].str.contains('quantised', na=True) | df_demographic['Question Key'].str.contains('response-2', na=True)\n",
        "df_demographic = df_demographic[~mask]\n",
        "df_demographic = df_demographic.dropna()\n",
        "#display(df_demographic)\n",
        "\n",
        "#Isolate relevant columns: Ethnic Identity\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_EthId = df_EthId[~df_EthId['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_EthId.drop(columns=df_EthId.columns.difference(include), inplace=True)\n",
        "mask = df_EthId['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_EthId['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_EthId = df_EthId[~mask]\n",
        "df_EthId = df_EthId.dropna()\n",
        "#display(df_EthId)\n",
        "\n",
        "#Isolate relevant columns: Multidimensional Inventory of Black Identity\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_MIBI = df_MIBI[~df_MIBI['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_MIBI.drop(columns=df_MIBI.columns.difference(include), inplace=True)\n",
        "mask = df_MIBI['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_MIBI['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_MIBI = df_MIBI[~mask]\n",
        "df_MIBI = df_MIBI.dropna()\n",
        "#display(df_MIBI)\n",
        "\n",
        "#Isolate relevant columns: News Consumption\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_News = df_News[~df_News['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_News.drop(columns=df_News.columns.difference(include), inplace=True)\n",
        "mask = df_News['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_News['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_News = df_News[~mask]\n",
        "df_News = df_News.dropna()\n",
        "#display(df_News)\n",
        "\n",
        "#Isolate relevant columns: Gender/Racial Discrimination\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_GRDiscrim = df_GRDiscrim[~df_GRDiscrim['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_GRDiscrim.drop(columns=df_GRDiscrim.columns.difference(include), inplace=True)\n",
        "mask = df_GRDiscrim['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_GRDiscrim['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_GRDiscrim = df_GRDiscrim[~mask]\n",
        "df_GRDiscrim = df_GRDiscrim.dropna()\n",
        "#display(df_GRDiscrim)\n",
        "\n",
        "#Isolate relevant columns: Concept Exposure\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_ConExposure = df_ConExposure[~df_ConExposure['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConExposure.drop(columns=df_ConExposure.columns.difference(include), inplace=True)\n",
        "mask = df_ConExposure['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConExposure['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConExposure = df_ConExposure[~mask]\n",
        "df_ConExposure = df_ConExposure.dropna()\n",
        "#display(df_ConExposure)\n",
        "\n",
        "#Isolate relevant columns: Concept Feeling\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_ConFeeling = df_ConFeeling[~df_ConFeeling['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConFeeling.drop(columns=df_ConFeeling.columns.difference(include), inplace=True)\n",
        "mask = df_ConFeeling['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConFeeling['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConFeeling = df_ConFeeling[~mask]\n",
        "df_ConFeeling = df_ConFeeling.dropna()\n",
        "#display(df_ConFeeling)\n",
        "\n",
        "#Isolate relevant columns: Concept Interaction\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_ConInteraction = df_ConInteraction[~df_ConInteraction['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_ConInteraction.drop(columns=df_ConInteraction.columns.difference(include), inplace=True)\n",
        "mask = df_ConInteraction['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_ConInteraction['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_ConInteraction = df_ConInteraction[~mask]\n",
        "df_ConInteraction = df_ConInteraction.dropna()\n",
        "#display(df_ConInteraction)\n",
        "\n",
        "#Isolate relevant columns: Social Dominance Orientation\n",
        "include = ['Participant Completion Code', 'Question Key', 'Response']\n",
        "#df_SDO = df_SDO[~df_SDO['Event Index'].str.contains('END OF FILE', na=True)]\n",
        "df_SDO.drop(columns=df_SDO.columns.difference(include), inplace=True)\n",
        "mask = df_SDO['Question Key'].str.contains('BEGIN QUESTIONNAIRE', na=True) | df_SDO['Question Key'].str.contains('END QUESTIONNAIRE', na=True)\n",
        "df_SDO = df_SDO[~mask]\n",
        "df_SDO = df_SDO.dropna()\n",
        "#display(df_SDO)\n",
        "\n",
        "#Isolate relevant columns: PRaM\n",
        "include = ['Participant Completion Code', 'Zone Name', 'conceptA', 'conceptB', 'Response']\n",
        "df_taskPRaM.drop(columns=df_taskPRaM.columns.difference(include), inplace=True)\n",
        "mask = df_taskPRaM['Zone Name'].str.contains('Likert', na=True)\n",
        "df_taskPRaM = df_taskPRaM[mask]\n",
        "df_taskPRaM = df_taskPRaM.dropna()\n",
        "df_taskPRaM.drop(columns=['Zone Name'], inplace=True)\n",
        "df_taskPRaM['Pair'] = df_taskPRaM['conceptA'] + '-' + df_taskPRaM['conceptB']\n",
        "df_taskPRaM.drop(columns=['conceptA', 'conceptB'], inplace=True)\n",
        "# display(df_taskPRaM)\n",
        "\n",
        "#Isolate relevant columns: SpAM\n",
        "include = ['Participant Completion Code', 'Zone Name', 'Zone Type', 'Response']\n",
        "df_taskSpAM = df_taskSpAM[:-1]\n",
        "mask = df_taskSpAM['Trial Number'].str.contains('BEGIN TASK', na=True) | df_taskSpAM['Trial Number'].str.contains('END TASK', na=True)\n",
        "df_taskSpAM = df_taskSpAM[~mask]\n",
        "df_taskSpAM.drop(columns=df_taskSpAM.columns.difference(include), inplace=True)\n",
        "mask = df_taskSpAM['Zone Type'].str.contains('drag_and_drop_main', na=True) | df_taskSpAM['Zone Name'].str.contains('Zone10', na=True) \n",
        "df_taskSpAM = df_taskSpAM[mask]\n",
        "df_taskSpAM.drop(columns=['Zone Type'], inplace=True)\n",
        "df_taskSpAM['Zone Name'] = df_taskSpAM['Zone Name'].replace(['conceptA', 'conceptB', 'conceptC', 'conceptD', 'conceptE', 'conceptF', 'conceptG'], ['Police', 'Firefighter', 'Neighbors', 'Conservatives', 'Liberals', 'Healthcare', 'Voting'])\n",
        "df_taskSpAM = df_taskSpAM.dropna()\n",
        "#display(df_taskSpAM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LwvqmKec1MJ",
        "outputId": "bca487c9-54c5-46f6-befe-3c7ff8dfd480"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n",
            "<ipython-input-38-324d87307e92>:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_taskSpAM['Zone Name'] = df_taskSpAM['Zone Name'].replace(['conceptA', 'conceptB', 'conceptC', 'conceptD', 'conceptE', 'conceptF', 'conceptG'], ['Police', 'Firefighter', 'Neighbors', 'Conservatives', 'Liberals', 'Healthcare', 'Voting'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Isolate Pivot dataframes\n",
        "df_demographic = df_demographic.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Demographics\n",
        "#display(df_demographic)\n",
        "\n",
        "df_EthId = df_EthId.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Ethnic Identity\n",
        "#display(df_EthId)\n",
        "\n",
        "df_MIBI = df_MIBI.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Multidimensional Inventory of Black Identity\n",
        "#display(df_MIBI)\n",
        "\n",
        "df_News = df_News.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #News Consumption\n",
        "#display(df_News)\n",
        "\n",
        "df_GRDiscrim = df_GRDiscrim.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Gender/Racial Discrimination\n",
        "#display(df_GRDiscrim)\n",
        "\n",
        "df_ConExposure = df_ConExposure.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Concept Exposure\n",
        "#display(df_ConExposure)\n",
        "\n",
        "df_ConFeeling = df_ConFeeling.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Concept Feeling\n",
        "#display(df_ConFeeling)\n",
        "\n",
        "df_ConInteraction = df_ConInteraction.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Concept Interaction\n",
        "#display(df_ConInteraction)\n",
        "\n",
        "df_SDO = df_SDO.pivot(index = 'Participant Completion Code', columns = ['Question Key'], values = ['Response']) #Social Dominance Orientation\n",
        "#display(df_SDO)\n",
        "\n",
        "#TASKS:\n",
        "#TODO: Take last mask out last instance of each concepts. If no isntance is present then use default coordinate. Flag participants that did not move at least half of the concepts (i.e., there are no entries)\n",
        "#df_taskSpAM_test = df_taskSpAM.pivot(index = 'Participant Completion Code', columns = ['Zone Name'], values = ['Response']) #SpAM\n",
        "#df_taskSpAM_test = df_taskSpAM_test.groupby(level=0).last()\n",
        "#display(df_taskSpAM_test)\n",
        "\n",
        "# Old code runs to \"ValueError: Index contains duplicate entries, cannot reshape\" isssue.\n",
        "# df_taskPRaM = df_taskPRaM.pivot(index = ['Participant Completion Code'], columns = ['Pair'], values = ['Response']) #PRaM\n",
        "# #display(df_taskPRaM)\n",
        "\n",
        "#Solution\n",
        "# group values by index column and aggregating the Response values as list. \n",
        "df_taskPRaM = df_taskPRaM.groupby(['Participant Completion Code', 'Pair'])['Response'].agg(list).reset_index()\n",
        "df_taskPRaM = df_taskPRaM.pivot(index='Participant Completion Code', columns='Pair', values='Response')\n",
        "\n",
        "# Run the following function to convert Response values from list to float.\n",
        "df_taskPRaM = df_taskPRaM.applymap(convert_to_float)\n",
        "#display(df_taskPRaM)"
      ],
      "metadata": {
        "id": "8dzVwNOoDY5V"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Push to Lab GitHub !!!\n",
        "#NOTE: These credentials should be configured to user's lab GitHub\n",
        "#If user is part of ExCaLBBR Lab then ask Roberto for access\n",
        "!git config --global user.name \"nmossazg12\" #\"YOUR CREDIENTIALS HERE\" \n",
        "!git config --global user.email \"anahom12@gmail.com\" #\"YOUR CREDIENTIALS HERE\"\n",
        "!git config --global user.password \"#Gezabanda123\" #\"YOUR CREDIENTIALS HERE\"\n",
        "\n",
        "token = ''\n",
        "username_organization = ''\n",
        "repo = ''\n",
        "outputDir = ''"
      ],
      "metadata": {
        "id": "P1hSBfkRJkYa"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone repository and move created files into output directory\n",
        "!git clone https://{token}@github.com/{username_organization}/{repo}"
      ],
      "metadata": {
        "id": "RToVhxKCJntE",
        "outputId": "73370358-ef48-418c-ffb2-883f89b520f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'github.com'...\n",
            "fatal: repository 'https://github.com//' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert all files to csv\n",
        "df_check.to_csv('check.csv')\n",
        "df_demographic.to_csv('demographic.csv')\n",
        "df_taskRGN.to_csv('taskRGN.csv')"
      ],
      "metadata": {
        "id": "GHGoq3mGSf5Q",
        "outputId": "5a267694-4bd9-479c-d628-e55de12c8a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-b82e6df96966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert all files to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'check.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_demographic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'demographic.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_taskRGN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taskRGN.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_check' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Move files to Clone repository\n",
        "!mv check.csv {repo}/{outputDir}\n",
        "!mv demographic.csv {repo}/{outputDir}\n",
        "!mv taskRGN.csv {repo}/{outputDir}"
      ],
      "metadata": {
        "id": "8QzFtkfER0-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move to principle dir, commit, and push changes\n",
        "%cd {repo}\n",
        "!git add --all\n",
        "!git commit -a -m \"Fixed issues with Isolate relevant columns: PRaM and SPaM\"\n",
        "!git push origin"
      ],
      "metadata": {
        "id": "GhSx52_aMfPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}