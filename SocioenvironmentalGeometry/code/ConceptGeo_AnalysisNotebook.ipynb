{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6bRsiw/GOWzyJmAb0bT1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExCaLBBR/ExCaLBBR_Projects/blob/main/SocioenvironmentalGeometry/code/ConceptGeo_AnalysisNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concept Geometry analysis pipeline \n",
        "Created by: <b>Roberto Vargas </b><br>\n",
        "Adapted from Octave by: <b>Nahom Mossazghi </b><br>\n",
        "<br>\n",
        "<b>Pipeline includes:</b><br>\n",
        "*   Data restructuring: Sorting accoring to word list\n",
        "*   Regression predicting pair differences\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "O4Gme4COyVnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependancies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt \n",
        "from scipy import stats \n",
        "from itertools import combinations\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import csv"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SEWVqBcKx9KO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define utility functions\n",
        "def weightedHeatmap(PairData, words, PlotHM):\n",
        "        \n",
        "    '''\n",
        "    Restructure RT into matrix data structure\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    Wmat = np.zeros((len(words),len(words))) \n",
        "    t = 0\n",
        "    z = 0\n",
        "    \n",
        "    for i in range(len(words)):\n",
        "        for j in range(len(words)):\n",
        "            \n",
        "            if i == j:\n",
        "                Wmat[i,j] = np.NaN\n",
        "            \n",
        "            elif j > i:\n",
        "                Wmat[i,j] = PairData[t]\n",
        "                Wmat[j,i] = PairData[t]            \n",
        "                t += 1  \n",
        "                \n",
        "                \n",
        "    if PlotHM == 1:\n",
        "        plt.imshow(Wmat, cmap='RdBu')\n",
        "        plt.colorbar()\n",
        "        plt.xticks(range(len(words)), words, rotation='vertical')\n",
        "        plt.yticks(range(len(words)), words)\n",
        "        plt.show()\n",
        "        \n",
        "    return Wmat\n",
        "        \n",
        "def ccbi_randperm(ntimes, nperm):\n",
        "    \n",
        "    '''\n",
        "      p = ccbi_randperm(nitems,nperm)\n",
        "      Parameters: number of items, number of random permutations\n",
        "      Output: a matrix with nperm rows;\n",
        "      Each row is an index of permuted item positions.\n",
        "    \n",
        "      returns a matrix (n,nitems)\n",
        "      each row is a random permutation of nitems (labelled 1:nitems)\n",
        "      produces n such permutations\n",
        "      the random seed is changed at every call\n",
        "      \n",
        "    '''\n",
        "    \n",
        "    p = np.zeros((nperm, ntimes))        \n",
        "    for i in range(nperm):\n",
        "        p[i,:] = np.random.permutation(ntimes)\n",
        "        \n",
        "    return p\n",
        "                 \n",
        "\n",
        "def splitHalf_Reliability(dat, perm):\n",
        "    \"\"\"\n",
        "    Compute the reliability within a measure\n",
        "    This analysis splits the data into 2 halfs and then averages the similarity structure\n",
        "    This analysis is repeated\n",
        "    \n",
        "    \"\"\"\n",
        "    pSplit = ccbi_randperm(dat.shape[1], perm)\n",
        "\n",
        "    rho = []\n",
        "    for p in range(perm):\n",
        "        # Split data\n",
        "        if dat.shape[1] % 2 == 0:  # is even\n",
        "            frstHalf = dat.iloc[:, pSplit[p, :(pSplit.shape[1]//2)]]\n",
        "            scndHalf = dat.iloc[:, pSplit[p, (pSplit.shape[1]//2):]]\n",
        "\n",
        "        elif dat.shape[1] % 2 == 1:  # is odd\n",
        "            frstHalf = dat.iloc[:, pSplit[p, :int(np.floor(pSplit.shape[1]/2))]]\n",
        "            scndHalf = dat.iloc[:, pSplit[p, int(np.ceil(pSplit.shape[1]/2)):]]\n",
        "        # Avg dist of each half\n",
        "        avgFrstHalf = frstHalf.mean(axis=1)\n",
        "        avgScndHalf = scndHalf.mean(axis=1)\n",
        "\n",
        "        # Correlate halves\n",
        "        rhoI = np.corrcoef(avgFrstHalf, avgScndHalf)[0,1]\n",
        "\n",
        "        rho.append(rhoI)\n",
        "    \n",
        "    rho = np.mean(rho)\n",
        "\n",
        "    return rho\n",
        "        \n",
        "\n",
        "\n",
        "def regPairDiff(dumX, cov, Y, perm):\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    Predict pair differences among a binary category in Y\n",
        " \tdumX is a dummy code variable being used to predict Y\n",
        " \tcov is a matrix of covariates included in the model\n",
        " \tY is a continuous vector \n",
        " \tperm is the number of permutations used to compare against the observed beta\n",
        "    Dimensions of duX, cov, and Y should all align\n",
        "    \n",
        "    '''    \n",
        "    \n",
        "    # Generate the permutations\n",
        "    pComb = ccbi_randperm(len(dumX),perm)\n",
        "    \n",
        "    # Generate constant\n",
        "    # con = np.ones(len(dumX),1)\n",
        "    \n",
        "    # Estimate observed beta\n",
        "    dumX =  dumX.reshape((dumX.shape[0],1))\n",
        "    xModel = np.concatenate((dumX, cov), axis=1)\n",
        "    betaObs = LinearRegression().fit(Y, xModel)\n",
        "    betaObs = betaObs.coef_[1]\n",
        "    \n",
        "    betaPerm = []\n",
        "    \n",
        "    for p in range(perm):\n",
        "        pCombi = pComb.astype(int)\n",
        "        xPermModel = np.concatenate((dumX[pComb[p,:]], cov), axis=1)\n",
        "        bPerm = LinearRegression().fit(Y,xPermModel)\n",
        "        betaPerm.append(bPerm.coef_[1])\n",
        "        \n",
        "    if betaObs > 0:\n",
        "        \n",
        "        nBbeyond = len(np.where((betaPerm>betaObs)))\n",
        "        pval = nBbeyond/perm\n",
        " \t    \n",
        "        \n",
        "    elif betaObs < 0:\n",
        " \t    nBbeyond = len(np.where(betaPerm<betaObs));\n",
        " \t    pval = nBbeyond/perm\n",
        "        \n",
        "    else:\n",
        "        raise ValueError('observed beta is exactly equal to 0')\n",
        "        \n",
        "    return betaObs, pval\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hlRGP67on-WW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data path\n",
        "path = 'https://github.com/ExCaLBBR/ExCaLBBR_Projects/raw/main/SocioenvironmentalGeometry/data/'\n",
        "\n",
        "# Load Demographic PRaM data\n",
        "datDemo = pd.read_csv (path + 'demographic.csv', header=1)\n",
        "datPRaM = pd.read_csv (path + 'df_taskPRaM.csv', header=0)\n",
        "pairLab = pd.read_csv (path + 'PRaM_pairLabels.csv', header=None)\n",
        "\n",
        "\n",
        "#Sort pairs accoring to prefered combination\n",
        "words = ['police', 'firefighter', 'neighbors(yours)', 'conservatives(political)', 'liberals(political)', 'healthcare', 'voting', 'immigration', 'religion', 'science', 'anger', 'fear', 'joy', 'love', 'sadness', 'trust']\n",
        "combinations_list = [list(c) for c in combinations(words, 2)]\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3gJYjXFp7Nu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOup7Ua01jOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-organize the dataframe according to the word combination\n",
        "wPairLabel = []\n",
        "x = []                  #index orders are saved as list\n",
        "for i in range(len(combinations_list)):\n",
        "    \n",
        "    # Extract pair rating\n",
        "    idx0 = pairLab[pairLab.iloc[:,1].str.contains(combinations_list[i][0].replace('(', r'\\(').replace(')', r'\\)'))].index\n",
        "    idx1 = pairLab[pairLab.iloc[:,2].str.contains(combinations_list[i][1].replace('(', r'\\(').replace(')', r'\\)'))].index\n",
        "    pIndx = idx0.intersection(idx1)\n",
        "    \n",
        "    # Extract pair label\n",
        "    wPairLabeli = combinations_list[i][0] + '-' + combinations_list[i][1]\n",
        "    wPairLabel.append(wPairLabeli)\n",
        "    x.append(pIndx[0])\n",
        "\n",
        "# Pair label rating    \n",
        "datPRaM_conSort = datPRaM.iloc[:,x]   \n",
        "datPRaM_conSort = datPRaM_conSort.rename(columns=dict(zip(datPRaM_conSort.columns, wPairLabel)))    \n",
        "wPairLabel = pd.DataFrame(wPairLabel)    "
      ],
      "metadata": {
        "id": "dqy5yr8OvNlQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to distance matrix\n",
        "Wmat = np.zeros((len(words), len(words)))    \n",
        "\n",
        "t = 0\n",
        "z = 0\n",
        "\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        \n",
        "        if i == j:\n",
        "            Wmat[i,j] = np.NaN\n",
        "        \n",
        "        elif j > i:\n",
        "            Wmat[i,j] = datPRaM_conSort.iloc[t,0]\n",
        "            Wmat[j,i] = datPRaM_conSort.iloc[t,0]\n",
        "            \n",
        "            t += 1"
      ],
      "metadata": {
        "id": "MHwieQDmzePw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Indx racial groups \n",
        "bIndx =  datDemo['raceEth_v2'][datDemo.iloc[:,0].str.contains('Black or African American')].index\n",
        "wIndx =  datDemo['raceEth_v2'][datDemo.iloc[:,0].str.contains('White')].index \n",
        "    \n",
        "bPRaM = datPRaM_conSort.iloc[bIndx,:]\n",
        "wPRaM = datPRaM_conSort.iloc[wIndx,:]"
      ],
      "metadata": {
        "id": "JgyUDylW1Yhe"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}